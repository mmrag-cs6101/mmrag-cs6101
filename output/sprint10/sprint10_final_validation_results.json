{
  "overall_accuracy": 0.025,
  "overall_confidence_interval": [
    0.0044267174077949195,
    0.1288165948800778
  ],
  "total_questions": 40,
  "total_correct": 1,
  "target_achieved": "False",
  "target_range": [
    0.53,
    0.59
  ],
  "scenario_results": {
    "angle": {
      "scenario_type": "angle",
      "total_samples": 10,
      "correct_answers": 0,
      "accuracy": 0.0,
      "confidence_interval_95": [
        0.0,
        0.2775401687666165
      ],
      "multi_run_stats": null,
      "avg_processing_time": 4.268217206001282,
      "avg_retrieval_time": 1.6214362144470216,
      "avg_generation_time": 2.630152130126953,
      "avg_confidence_score": 0.6599999999999999,
      "std_confidence_score": 0.11135528725660042,
      "error_rate": 0.0,
      "in_target_range": "False",
      "target_range": [
        0.53,
        0.59
      ]
    },
    "partial": {
      "scenario_type": "partial",
      "total_samples": 10,
      "correct_answers": 0,
      "accuracy": 0.0,
      "confidence_interval_95": [
        0.0,
        0.2775401687666165
      ],
      "multi_run_stats": null,
      "avg_processing_time": 1.8014732360839845,
      "avg_retrieval_time": 0.859881067276001,
      "avg_generation_time": 0.9150028228759766,
      "avg_confidence_score": 0.71,
      "std_confidence_score": 0.11357816691600543,
      "error_rate": 0.0,
      "in_target_range": "False",
      "target_range": [
        0.53,
        0.59
      ]
    },
    "scope": {
      "scenario_type": "scope",
      "total_samples": 10,
      "correct_answers": 0,
      "accuracy": 0.0,
      "confidence_interval_95": [
        0.0,
        0.2775401687666165
      ],
      "multi_run_stats": null,
      "avg_processing_time": 1.950564479827881,
      "avg_retrieval_time": 0.9406004667282104,
      "avg_generation_time": 0.9764576911926269,
      "avg_confidence_score": 0.7,
      "std_confidence_score": 0.1095445115010332,
      "error_rate": 0.0,
      "in_target_range": "False",
      "target_range": [
        0.53,
        0.59
      ]
    },
    "occlusion": {
      "scenario_type": "occlusion",
      "total_samples": 10,
      "correct_answers": 1,
      "accuracy": 0.1,
      "confidence_interval_95": [
        0.01787574951572113,
        0.4041563854975721
      ],
      "multi_run_stats": null,
      "avg_processing_time": 2.147731971740723,
      "avg_retrieval_time": 0.9045138835906983,
      "avg_generation_time": 1.212789034843445,
      "avg_confidence_score": 0.72,
      "std_confidence_score": 0.039999999999999994,
      "error_rate": 0.0,
      "in_target_range": "False",
      "target_range": [
        0.53,
        0.59
      ]
    }
  },
  "scenarios_in_target": 0,
  "scenario_consistency": 0.0,
  "num_evaluation_runs": 1,
  "multi_run_statistics": null,
  "cross_run_consistency": 1.0,
  "performance_metrics": {
    "avg_query_time": 2.5419967234134675,
    "p50_query_time": 2.049148225784302,
    "p95_query_time": 4.268217206001282,
    "p99_query_time": 4.268217206001282,
    "total_evaluation_time": 101.74831533432007,
    "peak_memory_gb": 5.948353290557861,
    "avg_memory_gb": 5.948353290557861,
    "memory_utilization_percent": 37.17720806598663,
    "memory_within_limit": true,
    "total_queries": 40,
    "successful_queries": 1,
    "failed_queries": 39,
    "success_rate": 0.025,
    "error_rate": 0.975,
    "queries_per_second": 0.39312690208746737,
    "samples_per_minute": 23.58761412524804
  },
  "statistical_confidence": "low",
  "baseline_comparison": null,
  "recommendations": [
    "CRITICAL: Accuracy 2.5% is 50.5% below target minimum (53.0%). Recommend: (1) Enhanced prompt engineering, (2) Increase retrieval top-k, (3) Lower generation temperature for more deterministic outputs.",
    "Scenario 'angle': 0.0% outside target. Apply scenario-specific prompt optimization and parameter tuning.",
    "Scenario 'partial': 0.0% outside target. Apply scenario-specific prompt optimization and parameter tuning.",
    "Scenario 'scope': 0.0% outside target. Apply scenario-specific prompt optimization and parameter tuning.",
    "Scenario 'occlusion': 10.0% outside target. Apply scenario-specific prompt optimization and parameter tuning.",
    "\u2713 Performance within target: 2.5s per query",
    "\u2713 Memory usage within limit: 5.9GB / 16.0GB",
    "Low statistical confidence - recommend: (1) Additional evaluation runs, (2) Larger sample sizes, (3) More consistent optimization",
    "NOT READY for production: Critical issues must be resolved"
  ],
  "production_readiness": "not_ready",
  "timestamp": "2025-11-12T00:50:08.317595",
  "total_validation_time": 104.16396045684814,
  "configuration_summary": {
    "model": {
      "vlm": "llava-hf/llava-onevision-qwen2-7b-ov-hf",
      "retriever": "openai/clip-vit-base-patch32",
      "quantization": "4bit"
    },
    "retrieval": {
      "top_k": 9,
      "embedding_dim": 512
    },
    "generation": {
      "max_length": 10,
      "temperature": 0.1,
      "top_p": 0.9
    },
    "performance": {
      "memory_limit_gb": 16.0,
      "batch_size": 4
    }
  }
}