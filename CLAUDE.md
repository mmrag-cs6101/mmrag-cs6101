# MRAG-Bench Reproduction System - Claude Code Guide

This document provides comprehensive guidance for using Claude Code with the MRAG-Bench reproduction system.

## ğŸ¯ Project Overview

This is a **fresh implementation** of a multimodal retrieval-augmented generation system designed to reproduce MRAG-Bench paper results. The system targets **53-59% accuracy** on perspective change scenarios using:

- **LLaVA-1.5-7B** (Vision-Language Model)
- **CLIP ViT-B/32** (Image Retriever)
- **4-bit quantization** for memory efficiency
- **16GB VRAM constraint** optimization

## ğŸš€ Quick Start with Claude Code

### Environment Setup (Required)

**âš ï¸ CRITICAL: Always use virtual environment for all operations**

```bash
# 1. Create virtual environment (UV recommended - 10x faster)
uv venv mrag-bench-env --python 3.10

# 2. Activate virtual environment (REQUIRED for all commands)
source mrag-bench-env/bin/activate

# 3. Install dependencies
uv pip install -r requirements.txt
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. Verify setup
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
python -c "from src.config import MRAGConfig; print('âœ… MRAG-Bench system ready')"
```

### Custom Claude Code Commands

This project includes custom commands for streamlined development:

```bash
# Product planning and requirements
/plan-and-analyze "multimodal RAG system features"

# Technical architecture design
/architect

# Sprint planning and task breakdown
/sprint-plan

# Sprint implementation with review cycle
/implement sprint-1    # Foundation setup
/implement sprint-2    # Dataset processing
/implement sprint-3    # CLIP retrieval
```

## ğŸ“‹ Sprint-Based Development

### Current Sprint Status

| Sprint | Status | Focus | Duration | Deliverables |
|--------|--------|-------|----------|--------------|
| **Sprint 1** | âœ… Complete | Foundation | Days 1-2.5 | Interfaces, config, memory mgmt |
| **Sprint 2** | âœ… Complete | Dataset | Days 3-5.5 | MRAG-Bench data processing |
| **Sprint 3** | ğŸ”„ Ready | Retrieval | Days 6-8.5 | CLIP image retrieval |
| **Sprint 4** | â³ Pending | Integration | Days 9-11.5 | End-to-end pipeline |
| **Sprint 5** | â³ Pending | Optimization | Days 12-14.5 | Performance tuning |

### Sprint Implementation

Each sprint follows a structured implementation and review cycle:

```bash
# Always activate environment first
source mrag-bench-env/bin/activate

# Run sprint implementation
/implement sprint-{number}

# Review implementation report
cat docs/a2a/reviewer.md

# Test implementation
python -m pytest tests/ -v
```

## ğŸ—ï¸ System Architecture

### Core Components

```
MRAG-Bench System Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dataset       â”‚    â”‚    Retrieval     â”‚    â”‚   Generation    â”‚
â”‚   Interface     â”‚â”€â”€â†’ â”‚    Pipeline      â”‚â”€â”€â†’ â”‚    Pipeline     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MRAG-Bench      â”‚    â”‚ CLIP ViT-B/32    â”‚    â”‚ LLaVA-1.5-7B    â”‚
â”‚ Data Loader     â”‚    â”‚ + FAISS Index    â”‚    â”‚ + 4-bit Quant   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Structure

```python
# Dataset Processing (Sprint 2 - Complete)
from src.dataset import MRAGDataset, DatasetInterface, ImagePreprocessor
from src.dataset import MemoryAwareDataLoader, DatasetValidator

# Retrieval System (Sprint 3 - In Progress)
from src.retrieval import RetrievalPipeline, CLIPRetriever
from src.retrieval import VectorStore, SimilaritySearch

# Generation System (Sprint 4 - Pending)
from src.generation import GenerationPipeline, LLaVAModel
from src.generation import QuantizedInference, ResponseGenerator

# Evaluation Framework (Sprint 5 - Pending)
from src.evaluation import MRAGBenchEvaluator, EvaluationResults
from src.evaluation import AccuracyMetrics, PerformanceTracker

# Utilities (Sprint 1 - Complete)
from src.utils import MemoryManager, ErrorHandler
from src.config import MRAGConfig
```

## ğŸ§ª Testing and Validation

### Testing Requirements

**All tests must run in virtual environment:**

```bash
# Activate environment (REQUIRED)
source mrag-bench-env/bin/activate

# Run comprehensive test suite
python -m pytest tests/ -v --cov=src --cov-report=term-missing

# Run specific component tests
python -m pytest tests/test_dataset.py -v      # Dataset processing
python -m pytest tests/test_memory_manager.py -v  # Memory management
python -m pytest tests/test_config.py -v      # Configuration system
```

### Validation Checklist

- âœ… **Environment Setup**: Virtual environment activated
- âœ… **GPU Detection**: CUDA available, RTX 5070Ti detected
- âœ… **Memory Management**: <15GB VRAM usage
- âœ… **Module Imports**: All core components import successfully
- âœ… **Configuration**: YAML config loads properly
- âœ… **Dataset Processing**: MRAG-Bench data pipeline operational

### Performance Targets

| Metric | Target | Current Status |
|--------|--------|----------------|
| **Accuracy** | 53-59% | Sprint 3+ |
| **Memory Usage** | â‰¤15GB VRAM | âœ… <1GB (Sprint 2) |
| **Dataset Loading** | <30s | âœ… <5s (Sprint 2) |
| **Processing Time** | <30s per query | Sprint 4+ |
| **Test Coverage** | >90% | âœ… 96% (Sprint 2) |

## ğŸ”§ Development Workflow

### Starting a Development Session

```bash
# 1. ALWAYS start by activating virtual environment
source mrag-bench-env/bin/activate

# 2. Verify environment is working
python -c "
import torch
from src.config import MRAGConfig
from src.utils.memory_manager import MemoryMonitor

print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA: {torch.cuda.is_available()}')
print(f'âœ… GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')
print(f'âœ… MRAG-Bench system ready')
"

# 3. Run development commands
```

### Code Development

```bash
# Always work in virtual environment
source mrag-bench-env/bin/activate

# Edit code with proper imports
python -c "
# Example: Test dataset functionality
from src.dataset import MRAGDataset
from src.config import MRAGConfig

config = MRAGConfig()
print(f'Dataset config: {config.dataset.data_path}')
"

# Run tests after changes
python -m pytest tests/test_your_changes.py -v
```

### Sprint Implementation

```bash
# Environment setup
source mrag-bench-env/bin/activate

# Check current sprint status
cat docs/sprint.md

# Implement next sprint
/implement sprint-3

# Review results
cat docs/a2a/reviewer.md
```

## ğŸ“ File Structure

```
mmrag-cs6101/
â”œâ”€â”€ mrag-bench-env/                 # ğŸ”´ Virtual environment (REQUIRED)
â”‚   â”œâ”€â”€ bin/activate               # Environment activation script
â”‚   â”œâ”€â”€ lib/python3.10/           # Python packages
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .claude/                       # Claude Code configuration
â”‚   â”œâ”€â”€ commands/                  # Custom commands
â”‚   â”‚   â”œâ”€â”€ plan-and-analyze.md    # Product planning
â”‚   â”‚   â”œâ”€â”€ architect.md           # Technical architecture
â”‚   â”‚   â”œâ”€â”€ sprint-plan.md         # Sprint planning
â”‚   â”‚   â””â”€â”€ implement.md           # Sprint implementation
â”‚   â””â”€â”€ agents/                    # Specialized agents
â”œâ”€â”€ src/                           # Core system implementation
â”‚   â”œâ”€â”€ dataset/                   # MRAG-Bench dataset processing
â”‚   â”‚   â”œâ”€â”€ interface.py           # Abstract interfaces
â”‚   â”‚   â”œâ”€â”€ mrag_dataset.py        # Core dataset implementation
â”‚   â”‚   â”œâ”€â”€ preprocessing.py       # Image preprocessing
â”‚   â”‚   â”œâ”€â”€ data_loader.py         # Memory-aware loading
â”‚   â”‚   â””â”€â”€ validation.py          # Dataset validation
â”‚   â”œâ”€â”€ retrieval/                 # CLIP-based retrieval (Sprint 3)
â”‚   â”œâ”€â”€ generation/                # LLaVA-based generation (Sprint 4)
â”‚   â”œâ”€â”€ evaluation/                # MRAG-Bench evaluation (Sprint 5)
â”‚   â”œâ”€â”€ utils/                     # Utilities and helpers
â”‚   â”‚   â”œâ”€â”€ memory_manager.py      # VRAM monitoring
â”‚   â”‚   â”œâ”€â”€ error_handling.py      # Error recovery
â”‚   â”‚   â””â”€â”€ optimization.py        # Performance optimization
â”‚   â””â”€â”€ config.py                  # Configuration management
â”œâ”€â”€ config/
â”‚   â””â”€â”€ mrag_bench.yaml            # System configuration
â”œâ”€â”€ docs/                          # Documentation
â”‚   â”œâ”€â”€ prd.md                     # Product Requirements Document
â”‚   â”œâ”€â”€ sdd.md                     # Software Design Document
â”‚   â”œâ”€â”€ sprint.md                  # Sprint Implementation Plan
â”‚   â””â”€â”€ a2a/                       # Agent-to-agent communication
â”‚       â”œâ”€â”€ reviewer.md            # Implementation reports
â”‚       â””â”€â”€ engineer-feedback.md   # Review feedback
â”œâ”€â”€ tests/                         # Comprehensive test suite
â”œâ”€â”€ data/                          # Dataset storage (created at runtime)
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # User documentation
â””â”€â”€ CLAUDE.md                      # This file
```

## ğŸ¯ Success Metrics and Goals

### Primary Objectives

1. **Accuracy Target**: Achieve 53-59% accuracy on MRAG-Bench perspective change scenarios
2. **Memory Efficiency**: Operate within 16GB VRAM constraint (target â‰¤15GB)
3. **Performance**: Complete queries in <30 seconds
4. **Reliability**: >99% successful inference completion rate

### Development Quality

- **Test Coverage**: Maintain >90% test coverage
- **Code Quality**: Follow Python best practices and type hints
- **Documentation**: Comprehensive inline and external documentation
- **Memory Management**: Proactive VRAM monitoring and optimization

### Sprint Success Criteria

Each sprint has specific deliverables and acceptance criteria:

- **Sprint 1**: âœ… Foundation interfaces and infrastructure
- **Sprint 2**: âœ… Dataset processing pipeline (exceeded targets)
- **Sprint 3**: CLIP retrieval system with vector indexing
- **Sprint 4**: LLaVA integration and end-to-end pipeline
- **Sprint 5**: Performance optimization and accuracy validation

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### Virtual Environment Not Activated

```bash
# âŒ Error: ModuleNotFoundError: No module named 'src'
# âœ… Solution:
source mrag-bench-env/bin/activate
python your_script.py
```

#### CUDA/GPU Issues

```bash
# Check GPU in virtual environment
source mrag-bench-env/bin/activate
python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB')
"
```

#### Memory Issues

```bash
# Monitor memory usage
source mrag-bench-env/bin/activate
python -c "
from src.utils.memory_manager import MemoryMonitor
monitor = MemoryMonitor(memory_limit_gb=15.0)
stats = monitor.get_current_stats()
print(f'GPU Memory: {stats.gpu_allocated_gb:.1f}/{stats.gpu_total_gb:.1f}GB')
print(f'Utilization: {stats.gpu_utilization_percent():.1f}%')
"
```

#### Import Errors

```bash
# Fix import issues
source mrag-bench-env/bin/activate
python -c "
# Test all core imports
try:
    from src.config import MRAGConfig
    from src.dataset import DatasetInterface
    from src.utils.memory_manager import MemoryMonitor
    print('âœ… All imports successful')
except ImportError as e:
    print(f'âŒ Import error: {e}')
"
```

### Debug Commands

```bash
# Full system verification
source mrag-bench-env/bin/activate
python -c "
print('ğŸ” MRAG-Bench System Debug')
print('=' * 40)

# Environment
import sys
print(f'Python: {sys.version}')

# PyTorch
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.cuda.is_available()}')

# System components
from src.config import MRAGConfig
from src.utils.memory_manager import MemoryMonitor

config = MRAGConfig()
monitor = MemoryMonitor()
stats = monitor.get_current_stats()

print(f'Model: {config.model.vlm_name}')
print(f'Memory: {stats.gpu_allocated_gb:.1f}/{stats.gpu_total_gb:.1f}GB')
print('âœ… System ready for development')
"
```

## ğŸ“– Best Practices

### Development Guidelines

1. **Always use virtual environment**: Every Python command must run in `mrag-bench-env`
2. **Follow sprint sequence**: Implement sprints in order (1â†’2â†’3â†’4â†’5)
3. **Test after changes**: Run relevant tests after any code modifications
4. **Monitor memory**: Use memory manager for VRAM-intensive operations
5. **Document changes**: Update relevant documentation for significant changes

### Code Standards

```python
# Example code structure
from typing import Optional, List, Dict, Any
from dataclasses import dataclass
import logging

logger = logging.getLogger(__name__)

@dataclass
class YourClass:
    """Clear docstring describing the class."""
    param: str
    optional_param: Optional[int] = None

    def your_method(self, input_data: List[str]) -> Dict[str, Any]:
        """
        Clear method documentation.

        Args:
            input_data: Description of input parameter

        Returns:
            Description of return value
        """
        try:
            # Implementation with proper error handling
            result = self._process_data(input_data)
            logger.info(f"Processed {len(input_data)} items")
            return result
        except Exception as e:
            logger.error(f"Error in your_method: {e}")
            raise
```

### Memory Management

```python
# Use memory manager for GPU operations
from src.utils.memory_manager import MemoryManager

manager = MemoryManager(memory_limit_gb=15.0)

# Check memory before operations
if manager.check_memory_availability(required_gb=5.0):
    # Proceed with GPU operation
    pass
else:
    # Handle memory constraint
    manager.clear_gpu_memory()
```

## ğŸš€ Next Steps

### Immediate Actions

1. **Activate virtual environment**: `source mrag-bench-env/bin/activate`
2. **Verify setup**: Run verification commands above
3. **Review current sprint**: Check `docs/sprint.md` for status
4. **Continue development**: Run `/implement sprint-3` for next phase

### Long-term Goals

- **Sprint 3**: Implement CLIP-based image retrieval with FAISS indexing
- **Sprint 4**: Integrate LLaVA-1.5-7B with quantization
- **Sprint 5**: Optimize performance and validate accuracy targets
- **Beyond**: Extend to other MRAG-Bench scenarios and evaluations

---

**âš ï¸ Remember: Virtual environment activation is required for ALL operations!**

```bash
# Always start with this
source mrag-bench-env/bin/activate
```

This ensures consistent behavior and proper dependency management throughout the development process.